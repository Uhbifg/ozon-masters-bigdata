{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "treated-exhaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "SPARK_HOME = \"/usr/hdp/current/spark2-client\"\n",
    "PYSPARK_PYTHON = \"/opt/conda/envs/dsenv/bin/python\"\n",
    "os.environ[\"PYSPARK_PYTHON\"]= PYSPARK_PYTHON\n",
    "os.environ[\"SPARK_HOME\"] = SPARK_HOME\n",
    "os.environ[\"PYTHONHASHSEED\"] = \"42\"\n",
    "PYSPARK_HOME = os.path.join(SPARK_HOME, \"python/lib\")\n",
    "sys.path.insert(0, os.path.join(PYSPARK_HOME, \"py4j-0.10.7-src.zip\"))\n",
    "sys.path.insert(0, os.path.join(PYSPARK_HOME, \"pyspark.zip\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "capable-official",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "import sys\n",
    "\n",
    "\n",
    "conf = SparkConf()\n",
    "sc = SparkContext(appName=\"hw_3_Uhbifg_1\", conf=conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "associate-stress",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_node = 1 # sys.argv[1]\n",
    "end_node = 99 # sys.argv[2]\n",
    "path_data = \"/datasets/twitter/twitter.tsv\"# sys.argv[3]\n",
    "path_ans = \"output_1\"# sys.argv[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "facial-bosnia",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_graph = sc.textFile(path_data)\n",
    "graph = raw_graph.map(lambda x: map(int, x.split(\"\\t\")[::-1])).cache()\n",
    "links = graph.groupByKey().partitionBy(sc.defaultParallelism).mapValues(list).cache()     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-pavilion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n",
      "2 0\n",
      "3 0\n",
      "4 0\n",
      "5 0\n",
      "6 0\n",
      "7 0\n",
      "8 0\n",
      "9 0\n",
      "10 0\n",
      "11 0\n",
      "12 0\n",
      "13 0\n",
      "14 0\n",
      "15 0\n",
      "16 0\n",
      "17 0\n",
      "18 0\n",
      "19 0\n",
      "20 0\n",
      "21 0\n",
      "22 0\n",
      "23 0\n",
      "24 0\n",
      "25 0\n",
      "26 0\n",
      "27 0\n",
      "28 0\n",
      "29 0\n",
      "30 0\n",
      "31 0\n",
      "32 0\n",
      "33 0\n",
      "34 0\n",
      "35 0\n",
      "36 0\n",
      "37 0\n",
      "38 0\n",
      "39 0\n",
      "40 0\n",
      "41 0\n",
      "42 0\n",
      "43 0\n",
      "44 0\n",
      "45 0\n",
      "46 0\n",
      "47 0\n",
      "48 0\n",
      "49 0\n",
      "50 0\n",
      "51 0\n",
      "52 0\n",
      "53 0\n",
      "54 0\n",
      "55 0\n",
      "56 0\n",
      "57 0\n",
      "58 0\n",
      "59 0\n",
      "60 0\n",
      "61 0\n",
      "62 0\n",
      "63 0\n",
      "64 0\n",
      "65 0\n",
      "66 0\n",
      "67 0\n",
      "68 0\n",
      "69 0\n",
      "70 0\n",
      "71 0\n",
      "72 0\n",
      "73 0\n",
      "74 0\n",
      "75 0\n",
      "76 0\n",
      "77 0\n",
      "78 0\n",
      "79 0\n",
      "80 0\n",
      "81 0\n",
      "82 0\n",
      "83 0\n",
      "84 0\n",
      "85 0\n",
      "86 0\n",
      "87 0\n",
      "88 0\n",
      "89 0\n",
      "90 0\n",
      "91 0\n",
      "92 0\n",
      "93 0\n",
      "94 0\n",
      "95 0\n",
      "96 0\n",
      "97 0\n",
      "98 0\n",
      "99 0\n",
      "100 0\n"
     ]
    }
   ],
   "source": [
    "w = dict(links.collect())\n",
    "def search(x1, x2, x3, seen):\n",
    "    ans = list()\n",
    "    a = x3[x1]\n",
    "    for i in a:\n",
    "        if i not in seen:\n",
    "            ans.append(tuple([i, x2 + [i]]))\n",
    "    return ans\n",
    "\n",
    "\n",
    "links = graph.groupByKey().mapValues(list).cache()     \n",
    "answers = []\n",
    "pathes = sc.parallelize([(start_node, [start_node])])\n",
    "seen = set([start_node])\n",
    "num = 0\n",
    "while True:\n",
    "    if num == 500:\n",
    "        ans = sc.parallelize([])\n",
    "        break\n",
    "    num += 1\n",
    "    print(num, pathes.count())\n",
    "    ans = pathes.filter(lambda x : x[0] == end_node)\n",
    "    if ans.count() > 0:\n",
    "        break\n",
    "    else:\n",
    "        rdd2 = pathes.map(lambda x : x[0], preservesPartitioning=True).distinct().collect()\n",
    "        neigbours = dict() \n",
    "        for i in rdd2:\n",
    "            neigbours[i] = w.get(i, [])\n",
    "        pathes = sc.parallelize(pathes.flatMap(lambda x : search(x[0], x[1], neigbours, seen), preservesPartitioning=True).collect())\n",
    "        seen.update(pathes.map(lambda x : x[0]).distinct().collect())\n",
    "ans = ans.map(lambda x : x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plastic-superintendent",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "asian-tolerance",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-432-3b8c3cf3b7a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "a = [1]\n",
    "a[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "magnetic-classics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[12, 422, 53, 52, 107, 20, 23, 274, 34]]"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "outstanding-venture",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ans = \"1.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "entitled-trunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = sc.parallelize([[1, 2, 3], [1, 3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "significant-vertical",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toCSVLine(data):\n",
    "    return ','.join(str(d) for d in data)\n",
    "\n",
    "lines = ans.map(toCSVLine)\n",
    "lines.saveAsTextFile(path_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "heated-fraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_rdd = sc.textFile(path_ans + \"1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "civil-draft",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,2,3', '1,3,4']"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "distant-operations",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,2,3', '1,3,4']"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "altered-cassette",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 items\r\n",
      "drwx------   - Uhbifg Uhbifg          0 2021-03-15 06:00 .Trash\r\n",
      "drwxr-xr-x   - Uhbifg Uhbifg          0 2021-03-03 14:12 .hiveJars\r\n",
      "drwxr-xr-x   - Uhbifg Uhbifg          0 2021-03-29 23:43 .sparkStaging\r\n",
      "drwx------   - Uhbifg Uhbifg          0 2021-02-24 14:46 .staging\r\n",
      "drwxr-xr-x   - Uhbifg Uhbifg          0 2021-03-29 23:58 1.csv\r\n",
      "drwxr-xr-x   - Uhbifg Uhbifg          0 2021-03-14 22:44 Uhbifg_hiveout\r\n",
      "drwx------   - Uhbifg Uhbifg          0 2021-02-15 10:40 hwzero\r\n",
      "drwxr-xr-x   - Uhbifg Uhbifg          0 2021-03-29 23:55 output\r\n",
      "drwxr-xr-x   - Uhbifg Uhbifg          0 2021-03-29 23:56 output_1\r\n",
      "drwxr-xr-x   - Uhbifg Uhbifg          0 2021-02-23 13:33 pred_with_filter\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "urban-specific",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: `1.csv': Is a directory\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -cat 1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "asian-flush",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authorized-graphic",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsenv",
   "language": "python",
   "name": "dsenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
